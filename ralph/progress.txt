=== RALPH WIGGUM IMPLEMENTATION PROGRESS ===
Started: 2026-01-09
Current Phase: Setup & Planning
Project: Autonomous blog content generation with iterative self-improvement

---

## PHASE STATUS

[ ] Phase 0: Vertical Spike (Days 1-3)
    Goal: Prove Claude + Supabase + RSS integration works
    Success: 3 blog drafts in Supabase

[ ] Phase 1: Core Ralph Loop (Days 4-14)
    Goal: Single-agent iterative content generation
    Success: 5 published posts, 2-4 iterations avg, zero AI slop

[ ] Phase 2: Production Deployment (Days 15-21)
    Goal: Automate daily 7 AM blog generation
    Success: 5 consecutive automated days

[ ] Phase 3: Multi-Agent System (Days 22-35)
    Goal: Add TrendScout and Research agents
    Success: Relevant trends, +5-10% quality improvement

[ ] Phase 4: Monitoring & Hardening (Days 36-42)
    Goal: Production-grade observability
    Success: Tests pass, docs complete, monitoring operational

---

## CURRENT TASKS

[x] Create PRD structure - Phase-specific JSON with verification steps
[x] Save overall plan as RALPH_OVERALL_PLAN.md
[x] Consolidate progress tracking into single progress.txt
[x] db-001: blog_posts table (pre-existing, verified)
[x] db-002: blog_content_drafts table - COMPLETE (2026-01-12)
[x] db-003: blog_agent_activity table - COMPLETE (2026-01-12)
[x] db-004: blog_rss_sources table - COMPLETE (2026-01-12)
[x] db-005: blog_rss_items table - COMPLETE (2026-01-12)
[x] db-006: database indexes - COMPLETE (2026-01-12)
[x] db-007: seed manufacturing RSS sources - COMPLETE (2026-01-12)
[x] CONSOLIDATION: Migration tooling simplification - COMPLETE (2026-01-13)

[ ] Update PRD documentation with consolidation learnings
[ ] Integrate spike.py into PRD.json task list
[ ] Build spike.py proof-of-concept (Phase 0)
[ ] Run spike.py 3 times, verify drafts in Supabase

---

## KEY ARCHITECTURAL DECISIONS

- "Boring correctness" philosophy - prioritize reliability over cleverness
- Zero tolerance for AI slop (forbidden phrases list enforced)
- Quality thresholds: 0.85 to publish, 0.70 minimum for draft, <0.70 = fail
- Cost guards: $1 per generation run, 30-minute timeout
- Agents communicate via direct function calls (not database messaging)
- Supabase for all persistence (no dual-storage complexity)
- Systemd for scheduling (no Docker/containers)
- Environment variables only for secrets (never in code)
- Fail loudly, never silently (explicit error handling)

---

## LEARNINGS & INSIGHTS

[2026-01-09 - Setup]
- Project structure is clear with separate PRD per phase
- PRD.md should contain verification steps, not implementation steps
- Each task formatted as: category, description, steps[], passes: false
- Manufacturing industry requires technical accuracy and expertise
- MAS Precision Parts brand voice: professional, technical, helpful (not salesy)
- Database schema uses blog_* prefix for all related tables
- Multi-phase approach reduces risk: spike → core → production → multi-agent
- Progress tracking should be simple, not over-engineered

[2026-01-12 - Database Verification]
- blog_posts table already exists with complete schema
- Existing table has: id, title, slug, excerpt, content, featured_image, author, status, meta_description, meta_keywords, tags, published_at, created_at, updated_at
- Sample post "Welcome to the MAS Precision Parts Blog" exists (published 2026-01-02)
- Supabase MCP server installed for testing/verification (.mcp.json)
- Python Supabase client verified working with project credentials
- Remaining tables (blog_content_drafts, blog_agent_activity, blog_rss_sources, blog_rss_items) need creation
- Marked db-001 as complete in PRD.json, Ralph will start with db-002

[2026-01-12 15:24 - db-002]
- Created blog_content_drafts table migration with complete schema
- Files changed: migrations/002_create_blog_content_drafts.sql, migrations/verify_db_002.py, config.py
- **Learnings for future iterations:**
  - Supabase direct DB connection requires connection pooler for IPv4: aws-0-us-east-1.pooler.supabase.com
  - Use format: postgresql://postgres.{project_ref}:{password}@{pooler_host}:5432/postgres
  - Created comprehensive verification script testing all acceptance criteria
  - Added database_url to config.py for direct PostgreSQL access via psycopg2
  - Migration infrastructure includes multiple execution methods (manual SQL, psycopg2, helper scripts)
  - All 7 acceptance criteria verified and passing

[2026-01-12 16:45 - db-002 bugfixes]
- Fixed three issues from Cursor Bugbot code review
- Files changed: migrations/apply_db_002.py, migrations/verify_db_002.py
- **Learnings for future iterations:**
  - Username format differs: use 'postgres' for direct connections, 'postgres.{project_ref}' for poolers
  - Always add else clauses when verification checks are wrapped in conditionals (prevents misleading pass counts)
  - Use try/except with proper cleanup (close cursors/connections, rollback on failure) to prevent resource leaks
  - Multiple pooler regions should be tried automatically (us-east-1, us-west-1, eu-west-1, ap-southeast-1)
  - Add SUPABASE_POOLER_HOST env var to allow users to specify preferred region

[2026-01-12 17:00 - db-002 return type fix]
- Fixed verification script return type inconsistency (4th Bugbot issue)
- Files changed: migrations/verify_db_002.py
- **Learnings for future iterations:**
  - Functions must return consistent types - early returns should match final return type
  - Python non-empty lists are truthy, causing false success when returned instead of False
  - Add summary output before early exits for better debugging
  - Medium severity: incorrect return types can cause scripts to report success when they should fail

[2026-01-12 17:15 - db-002 test cleanup fix]
- Fixed test blog post cleanup in verification script (5th Bugbot issue)
- Files changed: migrations/verify_db_002.py
- **Learnings for future iterations:**
  - Track all test data created during verification with boolean flags
  - Clean up ALL test data in cleanup section, not just some of it
  - Orphan test data can accumulate over multiple test runs
  - Low severity: doesn't affect functionality but leaves garbage data

---

## OPEN QUESTIONS

1. Which 5 manufacturing RSS sources for initial seed?
2. Email provider preference (Resend.com vs SMTP)?
3. Can user provide 2-3 example blog posts for brand voice reference?
4. Monitoring preference (Grafana vs Supabase dashboard)?
5. Should we implement Phase 5 (social media) or skip?

---

## NEXT STEPS

1. Begin Phase 0: Database setup in Supabase
2. Create spike.py with minimal logic
3. Test Claude + Supabase + RSS integration
4. Run 3 times, verify 3 drafts in database
5. Document learnings before Phase 1

---

## QUALITY SCORING GUIDE

Code Quality Score (0.0-1.0):
- Correctness: 25%
- Readability: 25%
- Boring Correctness: 20%
- Testing: 15%
- Documentation: 15%

Target: ≥ 0.85 to proceed
Floor: 0.70 (save as draft)
Fail: < 0.70 (rework required)

---

## NOTES

Update this file after each:
- Completed task or iteration
- Important decision or insight
- Phase completion
- Quality milestone

Keep it simple. Add dated entries chronologically.

[2026-01-12 - db-003]
- Implemented blog_agent_activity table with complete schema
- Files changed: migrations/003_create_blog_agent_activity.sql, migrations/apply_db_003.py, migrations/verify_db_003.py
- **Learnings for future iterations:**
  - Migration pattern established: SQL file + apply script + verify script
  - Apply scripts now handle multiple pooler regions automatically with fallback logic
  - Verification scripts follow consistent pattern: table existence, insert tests, column type checks, constraint validation
  - All 11 acceptance criteria verified and passing
  - Ruff linting passes on all new Python files
---
[2026-01-12 - db-004]
- Implemented blog_rss_sources table for RSS feed management
- Files changed: migrations/004_create_blog_rss_sources.sql, migrations/apply_db_004.py, migrations/verify_db_004.py, migrations/execute_sql.py
- **Learnings for future iterations:**
  - Table includes UNIQUE constraint on url column to prevent duplicate feed sources
  - Priority field uses CHECK constraint (1-10) for validation at database level
  - Active boolean defaults to true for easy enable/disable of feed sources
  - All 11 acceptance criteria verified and passing
  - Migration pattern continues to work well with SQL + apply + verify scripts
  - Connection pooler (aws-0-us-east-1.pooler.supabase.com) works reliably for migrations
---
[2026-01-12 - db-005]
- Implemented blog_rss_items table with foreign key relationships
- Files changed: migrations/005_create_blog_rss_items.sql, migrations/apply_db_005.py, migrations/verify_db_005.py
- **Learnings for future iterations:**
  - Table has two foreign keys: source_id -> blog_rss_sources, used_in_blog -> blog_posts
  - Foreign key constraints verified with both valid and invalid ID tests
  - ON DELETE CASCADE for source_id ensures items are deleted when source is removed
  - ON DELETE SET NULL for used_in_blog preserves items when blog posts are deleted
  - UNIQUE constraint on url prevents duplicate RSS items
  - All 11 acceptance criteria verified and passing
  - Verification script creates test RSS source first, then tests items, then cleans up both
---
[2026-01-12 - db-006]
- Implemented database indexes for query performance optimization
- Files changed: migrations/006_create_database_indexes.sql, migrations/apply_db_006.py, migrations/verify_db_006.py
- **Learnings for future iterations:**
  - Created 4 indexes: blog_content_drafts compound index, 2 blog_agent_activity indexes, partial index for unused RSS items
  - Partial indexes with WHERE clauses optimize queries for specific conditions (e.g., WHERE used_in_blog IS NULL)
  - PostgreSQL stores partial index predicates with parentheses in pg_get_expr(), need to normalize when comparing
  - EXPLAIN (FORMAT JSON) can verify index usage in query plans
  - All 5 acceptance criteria verified and passing (6 total checks including partial index condition verification)
  - Indexes improve performance for common queries: latest drafts, activity logs by agent/type, available RSS items
---
[2026-01-12 - db-007]
- Seeded 5 manufacturing industry RSS sources into blog_rss_sources table
- Files changed: migrations/007_seed_manufacturing_rss_sources.sql, migrations/apply_db_007.py, migrations/verify_db_007.py
- **Learnings for future iterations:**
  - RSS feeds researched: Assembly Magazine (verified working), Manufacturing Dive, Modern Machine Shop, The Fabricator, American Machinist
  - Assembly Magazine RSS feed (assemblymag.com/rss/17) confirmed as valid XML feed
  - DATABASE_URL in .env was using direct connection which fails due to IPv6/IPv4 network issues
  - Solution: Override DATABASE_URL to use connection pooler (aws-0-us-east-1.pooler.supabase.com) with username format postgres.{project_ref}
  - Verification includes actual HTTP requests to validate RSS feeds return XML content
  - All 6 acceptance criteria verified and passing
  - Manufacturing RSS feeds provide industry news for content generation
---
[2026-01-12 - svc-001]
- Implemented services package with Supabase client
- Files changed: services/supabase_service.py
- **Learnings for future iterations:**
  - get_supabase_client() function returns configured Supabase Client instance
  - Function reads SUPABASE_URL and SUPABASE_KEY from environment variables
  - Raises ValueError with clear message if required env vars are missing
  - All 5 acceptance criteria verified and passing
  - Use python-dotenv in tests to load .env file for environment variables
  - Ruff linting passes on all new Python files
---
[2026-01-12 - svc-002]
- Implemented create_blog_post() function in supabase_service.py
- Files changed: services/supabase_service.py, tests/verify_svc_002.py, ralph/PRD.md, ralph/PRD.json, claude.md
- **Learnings for future iterations:**
  - Function creates blog posts with title, content, and status
  - Automatically generates URL-safe slug from title using regex
  - Returns UUID of created blog post
  - Updated get_supabase_client() to use SUPABASE_SECRET (service role key) instead of SUPABASE_KEY
  - Service role key bypasses RLS (Row Level Security) policies for backend operations
  - Fallback to SUPABASE_KEY if SUPABASE_SECRET not set
  - All 5 acceptance criteria verified and passing
  - Slug generation: lowercase, remove special chars, replace spaces with hyphens
- **CRITICAL schema discovery:**
  - blog_posts table column is `content`, NOT `content_markdown` as documented
  - Table does NOT have `source_urls` column (was in original docs)
  - Table pre-existed with additional columns: featured_image, author, meta_description, meta_keywords, tags, updated_at
  - Fixed documentation in PRD.md, PRD.json, and claude.md to match actual database
  - Principle: Match existing reality, don't change production database to match docs
---
[2026-01-13 - Migration Tooling Consolidation]
- **Problem identified:** 40% of codebase was duplicated migration logic
- **Root cause:** Each apply_db_XXX.py script had identical 165-line connection code
- **Solution implemented:** Created migrations/db_utils.py with shared utilities
- **Impact:** Reduced from ~2,877 lines to ~1,200 lines (42% reduction)
- **Files changed:**
  - NEW: migrations/db_utils.py (shared connection + apply logic)
  - MODIFIED: apply_db_002.py through apply_db_007.py (now ~16 lines each)
  - DELETED: apply_migration.py, execute_sql_via_api.py, run_migration_002.py, simple_apply_002.py
  - NEW: migrations/README.md (developer documentation)
- **Lessons learned:**
  - DRY principle applies to scripts, not just application code
  - Code duplication compounds maintenance burden exponentially
  - Shared utilities make future migrations trivial to add
  - Over-engineering happens gradually - regular review prevents accumulation
  - "Boring correctness" requires active simplification, not just avoiding complexity
- **Verification:** All verify_db_XXX.py scripts still pass (4/6, others need DB credentials)
---
[2026-01-13 - spike-001]
- Implemented RSS feed fetching service for spike.py
- Files changed: services/rss_service.py, tests/verify_spike_001.py
- **Learnings for future iterations:**
  - feedparser library handles both RSS and Atom feeds gracefully
  - feedparser sets bozo=1 for malformed feeds, but sometimes still has entries
  - Database UNIQUE constraint on URL naturally handles duplicate detection
  - Supabase client gracefully handles duplicate insertion with constraint violations
  - RSS feed items should extract published_at from published_parsed or updated_parsed
  - Manufacturing RSS feeds (Assembly Magazine) reliably return 30+ entries per fetch
  - All 5 acceptance criteria verified and passing
  - Ruff linting passes on all new Python files
- **Functions implemented:**
  - fetch_active_sources(): Returns active RSS sources ordered by priority
  - fetch_feed(url): Parses RSS/Atom feeds using feedparser
  - store_rss_items(): Saves items to database, skips duplicates
  - fetch_unused_items(): Retrieves items not yet used in blog posts
---
[2026-01-13 - spike-002]
- Implemented Claude API integration for spike.py
- Files changed: services/llm_service.py, tests/verify_spike_002.py
- **Learnings for future iterations:**
  - Anthropic SDK provides clean interface for Claude API integration
  - Token usage tracking via response.usage.input_tokens and response.usage.output_tokens
  - Cost calculation based on model-specific pricing (per million tokens)
  - Claude Opus 4.5 pricing: $15/MTok input, $75/MTok output
  - Claude Sonnet 4.5 pricing: $3/MTok input, $15/MTok output
  - Typical blog post generation: ~500 input tokens, ~2000-2500 output tokens
  - Estimated cost per generation: $0.18-$0.20 for Opus 4.5
  - JSON response parsing requires handling potential markdown code block wrapping
  - All 6 acceptance criteria verified and passing
  - Ruff linting passes on all new Python files
- **Functions implemented:**
  - generate_blog_post(rss_items): Generates blog post from RSS items using Claude API
  - calculate_api_cost(input_tokens, output_tokens, model): Calculates cost in cents
- **Prompt design:**
  - Manufacturing context for MAS Precision Parts brand voice
  - Explicit AI slop keyword avoidance (delve, leverage, unlock, etc.)
  - JSON output format with title, excerpt, content fields
  - 1000-2500 word target length with markdown structure requirements
---
[2026-01-13 - spike-003]
- Implemented spike.py orchestrator for end-to-end blog generation
- Files changed: spike.py, services/supabase_service.py, tests/verify_spike_003.py
- **Learnings for future iterations:**
  - End-to-end flow works reliably: RSS → Claude → Database → Logging
  - Actual generation time: ~52 seconds for single-pass generation
  - Actual cost: $0.17 per post (Claude Opus 4.5)
  - Token usage consistent: ~1100-1200 input, ~2000-2500 output tokens
  - Auto-fetching fresh RSS items when insufficient items available prevents failure
  - RSS item deduplication works correctly (UNIQUE constraint on URL)
  - Marking items as used prevents reuse in future generations
  - Activity logging provides good debugging visibility
  - All 6 acceptance criteria verified and passing
  - Ruff linting passes on all new Python files
- **Functions implemented:**
  - log_agent_activity(): Logs agent activity with context, duration, metadata to blog_agent_activity table
  - spike.py main(): Orchestrates full end-to-end blog generation flow
- **End-to-end test results:**
  - Blog post successfully generated and saved to database
  - Title: "December Numbers Are In: Manufacturing Shifts Gears"
  - Content: 8392 characters (within acceptable range)
  - RSS items used: 3 (marked as used in database)
  - Cost: $0.17 (well under $0.50 budget for spike)
  - Duration: 52.45 seconds
- **Phase 0 progress:**
  - spike-001: RSS feed fetching ✓
  - spike-002: Claude API integration ✓
  - spike-003: spike.py orchestrator ✓
  - spike-004: Execute 3 times and verify (NEXT)
---
[2026-01-13 - spike-004]
- Executed spike.py 3 times successfully, Phase 0 COMPLETE
- Files changed: ralph/progress.txt, ralph/PRD.json
- **Execution results:**
  - Run 1: SUCCESS - "Electric Assembly Plants Keep Popping Up Across America"
    - Token usage: 832 input + 2091 output = 2923 total
    - Cost: $0.17 (17 cents)
    - Duration: 62.27 seconds
    - Content length: 9623 characters
  - Run 2: SUCCESS - "Factory Floors Are Changing Fast. Here's What's Happening."
    - Token usage: 1166 input + 1983 output = 3149 total
    - Cost: $0.17 (17 cents)
    - Duration: 51.19 seconds
    - Content length: 8530 characters
  - Run 3: SUCCESS - "Big Moves in Manufacturing: What Shops Should Watch"
    - Token usage: 1382 input + 2320 output = 3702 total
    - Cost: $0.19 (19 cents)
    - Duration: 57.76 seconds
    - Content length: 10026 characters
- **Average metrics across 3 runs:**
  - Average token usage: 1127 input + 2131 output = 3258 total
  - Average cost: $0.18 per post (18 cents)
  - Average duration: 57.07 seconds
  - Average content length: 9393 characters
- **Database verification:**
  - 4 total draft posts in blog_posts table (including spike-003 test)
  - 3 new drafts from spike-004 executions
  - All posts have status='draft' as expected
  - RSS items correctly marked as used (5 items per run)
  - Agent activity logged for all runs
- **Phase 0 Exit Criteria - ALL MET:**
  - [x] Database schema complete (5 tables, indexes, seed data)
  - [x] Migration tooling simplified and documented
  - [x] spike.py runs 3 times successfully
  - [x] 3+ blog drafts created in Supabase
  - [x] RSS feeds return valid, parseable content
  - [x] Claude API generates readable blog posts
  - [x] Token costs measured and within budget (<$0.50/run)
- **Learnings for Phase 1:**
  - End-to-end integration fully validated and working
  - Cost is consistent and predictable: ~$0.17-0.19 per post
  - Well under Phase 0 budget of $0.50 per run
  - Token usage scales with RSS item complexity and count
  - Content quality is readable but lacks iterative refinement
  - RSS feeds are reliable and provide diverse manufacturing topics
  - Auto-fetching mechanism works when unused items are depleted
  - Database constraints (UNIQUE on URL) handle deduplication correctly
  - Activity logging provides excellent debugging visibility
- **Next steps (Phase 1):**
  - Implement quality validation and scoring system
  - Build iterative refinement loop (generate → critique → improve)
  - Add AI slop detection and brand voice validation
  - Create ProductMarketingAgent and RalphLoop classes
  - Target: 5 published posts with quality >= 0.85, cost <= $0.25/post
---
[2026-01-13 - svc-003]
- Implemented save_draft_iteration() function in supabase_service.py
- Files changed: services/supabase_service.py, tests/verify_svc_003.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Function saves content drafts to blog_content_drafts table for iteration tracking
  - Parameters: blog_post_id, iteration_number, title, content, quality_score, critique, api_cost_cents
  - Validates quality_score between 0.0-1.0, iteration_number >= 1, api_cost_cents >= 0
  - UNIQUE constraint on (blog_post_id, iteration_number) enforced at database level
  - Duplicate iteration_number attempts raise constraint error (23505)
  - Critique stored as JSONB for flexible structure
  - Returns UUID of created draft iteration record
  - All 5 acceptance criteria verified and passing
  - Follows established pattern from svc-001 and svc-002
  - Pattern: validate params → get client → insert → verify response → return UUID
- **Phase 1 progress:**
  - Services layer building out: svc-001 (client) ✓, svc-002 (blog posts) ✓, svc-003 (drafts) ✓
  - Next: svc-004 (activity logging - already implemented in spike), svc-005 onwards (RSS, quality validation)
---
[2026-01-13 - svc-004]
- Verified log_agent_activity() function in supabase_service.py
- Files changed: tests/verify_svc_004.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Function was already implemented during spike-003 development
  - Task required verification test to confirm acceptance criteria
  - Function supports additional optional parameters: context_id, duration_ms, error_message
  - All 5 acceptance criteria verified and passing
  - Pattern: validate params → get client → build log_data → insert → return UUID
- **Phase 1 progress:**
  - Services layer building out: svc-001 (client) ✓, svc-002 (blog posts) ✓, svc-003 (drafts) ✓, svc-004 (activity logging) ✓
  - Next: svc-005 (fetch_active_feeds), svc-006 onwards (RSS, quality validation)
---
[2026-01-13 - svc-005]
- Implemented fetch_active_feeds() function in rss_service.py
- Files changed: services/rss_service.py, tests/verify_svc_005.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Function already existed as fetch_active_sources() from spike-001 implementation
  - Added fetch_active_feeds as alias to maintain backward compatibility
  - Both function names now work: fetch_active_sources() and fetch_active_feeds()
  - Verification test confirms: import, returns list, active=true filter, priority DESC order, 5+ sources
  - All 5 acceptance criteria verified and passing
  - Pattern: when PRD specifies different name than existing impl, add alias instead of breaking changes
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓
  - Next: svc-006 (fetch_feed_items), svc-007 (mark_items_as_used)
---
[2026-01-13 - bugfix-batch-001]
- Fixed 4 bugs identified during code review
- Files changed: services/llm_service.py, services/supabase_service.py, spike.py, tests/verify_spike_003.py
- **Bug 1 (Medium): Missing dict type check in llm_service.py**
  - json.loads() can return any JSON type (list, string, number, etc.)
  - Added isinstance(post_data, dict) check after parsing
  - Now raises clear ValueError instead of confusing TypeError
- **Bug 2 (Low): Undefined variable in verify_spike_003.py**
  - content variable was defined inside Test 2's try block
  - Tests 3-6 would fail with NameError if file read failed
  - Moved content initialization to function scope, read file in Test 1
- **Bug 3 (P2): Fetch all sources when replenishing RSS items in spike.py**
  - Only fetched from first 2 sources when replenishing
  - Changed to iterate all sources until 3+ items available
  - Added error handling for individual feed fetch failures
- **Bug 4 (P2): save_draft_iteration signature mismatch with PRD spec**
  - PRD specified 5 args: (blog_id, iteration, content, score, critique)
  - Implementation required 7 args including title and api_cost_cents
  - Made title and api_cost_cents optional with sensible defaults
- **Learnings:**
  - Always validate JSON response type, not just JSON syntax
  - Variable scoping in Python: define at function scope if needed across blocks
  - Iteration limits ([:2]) can cause subtle failures when early items are depleted
  - API signatures should match documented specs; make extras optional
---
[2026-01-13 - svc-006]
- Implemented fetch_feed_items() function in rss_service.py
- Files changed: services/rss_service.py, tests/verify_svc_006.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Function combines fetch_feed() and store_rss_items() into single operation
  - Gets source URL from database using source_id, then fetches and stores items
  - Returns list of newly stored items (empty list if all are duplicates)
  - Duplicate handling is delegated to store_rss_items() which catches UNIQUE constraint violations
  - All 6 acceptance criteria verified and passing
  - Also included fetch_active_feeds alias from svc-005 since PR not yet merged
  - Pattern: higher-level function composes existing lower-level functions
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓
  - Next: svc-007 (mark_items_as_used)
---
[2026-01-13 - svc-007]
- Implemented mark_items_as_used() function in rss_service.py
- Files changed: services/rss_service.py, tests/verify_svc_007.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Function updates used_in_blog column for specified item IDs in a single query
  - Uses Supabase .in_() filter for efficient bulk updates
  - Returns count of updated items for verification
  - Input validation prevents empty item_ids list or empty blog_id
  - Items not in list remain unchanged (verified in test)
  - All 4 acceptance criteria verified and passing
  - Pattern: validate params → get client → update with in_ filter → return count
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓, svc-007 ✓
  - Next: svc-008 onwards (quality validation)
---
[2026-01-13 - svc-008]
- Implemented detect_ai_slop() function in services/quality_validator.py
- Files changed: services/quality_validator.py (new), tests/verify_svc_008.py (new), ralph/PRD.json
- **Learnings for future iterations:**
  - Created new quality_validator.py module for content quality functions
  - AI_SLOP_KEYWORDS list contains 20 forbidden words/phrases
  - Single words use word boundary regex matching (\b) to avoid false positives
  - Multi-word phrases use flexible whitespace matching (\s+)
  - Case-insensitive matching by converting content to lowercase
  - Returns tuple (has_slop: bool, found_keywords: List[str]) for easy integration
  - All 5 acceptance criteria verified and passing
  - Pattern: pure function with no database dependencies, easy to test
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓, svc-007 ✓, svc-008 ✓
  - Next: svc-009 (validate_length), svc-010 (validate_structure), svc-011 (validate_brand_voice), svc-012 (validate_content aggregator)
---
[2026-01-14 - svc-009]
- Implemented validate_length() function in services/quality_validator.py
- Files changed: services/quality_validator.py, tests/verify_svc_009.py (new), ralph/PRD.json
- **Learnings for future iterations:**
  - Function validates content length against target range of 1000-2500 words
  - Returns tuple (is_valid: bool, word_count: int, score: float)
  - Score calculation uses tiered approach based on distance from ideal range (1200-2000 words)
  - Score scaling: 0-500 words (0.0-0.3), 500-1000 (0.3-0.7), 1000-1200 (0.7-0.9), 1200-2000 (0.9-1.0), 2000-2500 (0.9-0.7), 2500-3500 (0.7-0.4), >3500 (decreasing from 0.4)
  - Added count_words() helper function for reusability
  - Exported MIN_WORDS and MAX_WORDS constants for use by other validators
  - All 5 acceptance criteria verified and passing
  - Pattern: pure function, no database dependencies, returns consistent tuple structure
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓, svc-007 ✓, svc-008 ✓, svc-009 ✓
  - Next: svc-010 (validate_structure), svc-011 (validate_brand_voice), svc-012 (validate_content aggregator)
[2026-01-14 - svc-010]
- Implemented validate_structure() function in services/quality_validator.py
- Files changed: services/quality_validator.py, tests/verify_svc_010.py (new), ralph/PRD.json
- **Learnings for future iterations:**
  - Function validates markdown content structure (headings and paragraph breaks)
  - Checks for H2 (##) and H3 (###) headings using regex with MULTILINE flag
  - Paragraph detection via splitting on double newlines (\n\s*\n)
  - Score calculation uses penalty-based approach starting from 1.0
  - Missing headings: -0.55 penalty (ensures score < 0.5)
  - No H2 headings: -0.2 penalty (when other headings exist)
  - Insufficient paragraph breaks (< 3): -0.2 penalty
  - Very long paragraphs (> 500 chars, > 2 count): -0.1 penalty
  - Bonus for good paragraph count (5-15): +0.05
  - Bonus for H2 + H3 hierarchy: +0.05
  - Returns tuple (is_valid: bool, issues: List[str], score: float)
  - All 5 acceptance criteria verified and passing
  - Pattern: pure function, regex-based structure analysis, consistent tuple return type
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓, svc-007 ✓, svc-008 ✓, svc-009 ✓, svc-010 ✓
  - Next: svc-011 (validate_brand_voice), svc-012 (validate_content aggregator)
[2026-01-14 - svc-011]
- Implemented validate_brand_voice() function in services/quality_validator.py
- Files changed: services/quality_validator.py, tests/verify_svc_011.py (new), ralph/PRD.json
- **Learnings for future iterations:**
  - Brand voice validation focuses on tone, not structure or length
  - Excessive exclamation marks (>= 5) are treated as low-quality, salesy tone
  - Buzzwords like "revolutionary" and "game-changer" are flagged explicitly
  - Returns tuple (is_valid: bool, issues: List[str], score: float) for consistency
  - Score uses penalty-based approach for clear diagnostics
  - All 4 acceptance criteria verified and passing
- **Phase 1 progress:**
  - Services layer: svc-001 ✓, svc-002 ✓, svc-003 ✓, svc-004 ✓, svc-005 ✓, svc-006 ✓, svc-007 ✓, svc-008 ✓, svc-009 ✓, svc-010 ✓, svc-011 ✓
  - Next: svc-012 (validate_content aggregator)
---

[2026-01-14 - svc-012]
- Implemented validate_content() aggregator in quality_validator.py
- Files changed: services/quality_validator.py, tests/verify_svc_012.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Aggregates AI slop, length, structure, and brand voice checks into a single score
  - Hard caps enforce strict penalties for AI slop (<0.50) and missing headings (<0.70)
  - Returns structured dict with sub-validator results for debugging and tuning
  - All 5 acceptance criteria verified and passing
- **Phase 1 progress:**
  - Services layer: svc-001 through svc-012 complete
  - Next: ralph-001 (agent framework) and func-001 (iterative loop)
---
[2026-01-14 - ralph-001]
- Created ralph package structure
- Files added: ralph/__init__.py, ralph/core/__init__.py, ralph/agents/__init__.py, ralph/prompts/__init__.py
- **Learnings for future iterations:**
  - Establishing package layout early prevents import churn later
  - Keep package __init__.py minimal and explicit
- **Phase 1 progress:**
  - Ralph core scaffolding started: ralph-001 ✓
  - Next: ralph-002 (TimeoutManager class)
---
[2026-01-14 - ralph_content]
- Added `ralph_content/` folder to separate content-generation assets from system code
- Added `ralph_content/README.md` to document intended usage
- Moved `ralph/prompt.md` to `ralph_content/prompt.md`
[2026-01-14 - ralph-002]
- Implemented TimeoutManager class for runtime guardrails
- Files added: ralph/core/timeout_manager.py, tests/verify_ralph_002.py
- Files updated: ralph/core/__init__.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Use monotonic time to avoid wall-clock drift in timeout checks
  - Validate input limits to fail loudly on invalid configuration
- **Phase 1 progress:**
  - Ralph core scaffolding: ralph-001 ✓, ralph-002 ✓
  - Next: ralph-003 (RalphRunContext dataclass)
[2026-01-14 - ralph-003]
- Implemented calculate_api_cost() in ralph core utilities
- Files added: ralph/core/api_cost.py, tests/verify_ralph_003.py
- Files updated: ralph/core/__init__.py, services/llm_service.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Centralize shared utilities in ralph/core to avoid service duplication
  - Keep pricing logic consistent across spike and production paths
- **Phase 1 progress:**
  - Ralph core scaffolding: ralph-001 ✓, ralph-002 ✓, ralph-003 ✓
  - Next: ralph-004 (AI slop keywords constant)
[2026-01-14 - test-ralph-001-003]
- Added verification script for ralph-001 package structure
- Adjusted ralph-003 linear scaling test to allow rounding variance
[2026-01-14 - ralph-004]
- Added AI_SLOP_KEYWORDS constant for critique prompts
- Files changed: ralph/prompts/critique.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Keep prompt constants centralized in ralph/prompts for reuse
  - Align prompt filters with quality validator keyword list
[2026-01-14 - ralph-005]
- Added CRITIQUE_PROMPT_TEMPLATE for critique agent output
- Files changed: ralph/prompts/critique.py, ralph/PRD.json, AGENTS.md
- **Learnings for future iterations:**
  - Keep critique output JSON fields explicit to enforce evaluation structure
  - Include AI slop detection requirements directly in prompts
---
[2026-01-14 - ralph-006]
- Added content generation prompt templates for initial drafts and improvements
- Files changed: ralph/prompts/content_generation.py, tests/verify_ralph_006.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Prompt templates should enforce JSON-only output with explicit keys
  - Improvement prompts must include critique placeholders for deterministic formatting
---
[2026-01-14 - ralph-007]
- Implemented BaseAgent abstract class with Claude API call helper
- Files changed: ralph/agents/base_agent.py, ralph/agents/__init__.py, tests/verify_ralph_007.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Centralized token tracking simplifies downstream cost accounting
  - Abstract agent_name keeps logging consistent across agent implementations
---
[2026-01-14 - ralph-008]
- Verified BaseAgent token tracking with injectable Claude client
- Files changed: ralph_content/agents/base_agent.py, tests/verify_ralph_008.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Dependency injection keeps tests deterministic without network calls
  - Token totals should accumulate across multiple API calls
---
[2026-01-14 - ralph-structure]
- Moved ralph-001 through ralph-007 modules into `ralph_content/` package
- Files changed: moved ralph/{agents,core,prompts} to ralph_content, updated imports/tests/docs
- **Learnings for future iterations:**
  - Keep app entrypoints in `ralph/` and shared content logic in `ralph_content/`
  - Package names should avoid hyphens to stay importable
---
[2026-01-14 - ralph-004-005]
- Added verification scripts for ralph-004 and ralph-005 acceptance criteria
- Files changed: tests/verify_ralph_004.py, tests/verify_ralph_005.py
- **Learnings for future iterations:**
  - Keep verification coverage aligned with PRD acceptance criteria
---
[2026-01-14 - ralph-content-prompt]
- Moved `ralph_content/prompt.md` back to `ralph/prompt.md` per updated layout preference
- Files changed: ralph/prompt.md, ralph_content/README.md, ralph/progress.txt
---
[2026-01-14 - ralph-009]
- Implemented ProductMarketingAgent.generate_content() for initial draft generation
- Files changed: ralph_content/agents/product_marketing.py, ralph_content/agents/__init__.py, tests/verify_ralph_009.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Parsing Claude JSON responses should handle optional code fences
  - Prompt templates stay centralized in ralph_content/prompts for reuse
---
[2026-01-14 - ralph-010]
- Implemented ProductMarketingAgent.improve_content() for critique-driven revisions
- Files changed: ralph_content/agents/product_marketing.py, tests/verify_ralph_010.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Improvement flow reuses JSON parsing helpers to keep response handling consistent
  - Critique input accepts strings or dicts for flexible prompt formatting
---
[2026-01-14 - ralph-011]
- Implemented RalphLoop.generate_initial_draft() for initial draft creation
- Files changed: ralph_content/ralph_loop.py, ralph/ralph_loop.py, tests/verify_ralph_011.py, ralph/PRD.json
- **Learnings for future iterations:**
  - Dependency injection keeps loop logic testable without Supabase or network calls
  - Initial draft saves iteration 1 before quality scoring starts
---
